{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kaggle_tpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"/home/edu/code/google_fast_or_slow/data/npz_all/npz\")\n",
    "collection = \"layout/xla\"\n",
    "ctype = \"default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_graph(data):\n",
    "    print(\"Pruning graph...\")\n",
    "    new_data = deepcopy(dict(data))\n",
    "    print(\"Original graph has {} nodes and {} edges\".format(data[\"node_feat\"].shape[0], data[\"edge_index\"].shape[0]))\n",
    "    in_edge_index = data[\"edge_index\"][np.isin(data[\"edge_index\"], data[\"node_config_ids\"]).any(1)]\n",
    "\n",
    "    in_node_ids = np.unique(in_edge_index)\n",
    "    assert len(set(data[\"node_config_ids\"]) - set(in_node_ids)) == 0\n",
    "    lookup = np.ones(data[\"node_feat\"].shape[0]) * -1\n",
    "    lookup[in_node_ids] = np.arange(in_node_ids.shape[0])\n",
    "\n",
    "    in_node_feats = data[\"node_feat\"][in_node_ids, :]\n",
    "    in_node_opcode = data[\"node_opcode\"][in_node_ids]\n",
    "    in_edge_index = lookup[in_edge_index]\n",
    "    in_node_config_ids = lookup[data[\"node_config_ids\"]]\n",
    "\n",
    "    new_data[\"node_feat\"] = in_node_feats\n",
    "    new_data[\"node_opcode\"] = in_node_opcode\n",
    "    new_data[\"edge_index\"] = in_edge_index\n",
    "    new_data[\"node_config_ids\"] = in_node_config_ids\n",
    "    print(\"New graph has {} nodes and {} edges\".format(new_data[\"node_feat\"].shape[0], new_data[\"edge_index\"].shape[0]))\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupplicated_node_configs(data):\n",
    "    reshaped_config_feat = data[\"node_config_feat\"].reshape(data[\"node_config_feat\"].shape[0], -1) + 2 # avoid zeros\n",
    "    positional_array = np.random.random(reshaped_config_feat.shape[1])  # multiply each value by its position to avoid removing permutations by accident\n",
    "    reshaped_values = (reshaped_config_feat * positional_array[None, :]).sum(1)\n",
    "    is_equal_matrix = reshaped_values[None, :] == reshaped_values[:, None] # quadratic matrix of all pairwise equalities\n",
    "    # is_equal_matrix[np.triu_indices(is_equal_matrix.shape[0], 0)] = 0 # only get diagonal to avoid remove twice\n",
    "    is_equal_matrix = np.tril(is_equal_matrix, -1) # only get diagonal to avoid remove twice\n",
    "    to_remove_ids = np.unique(np.where(is_equal_matrix)[0])\n",
    "    print(\"Removing {} duplicated node configs out of {}\".format(to_remove_ids.shape[0], data[\"node_config_feat\"].shape[0]))\n",
    "    data[\"config_runtime\"] = np.delete(data[\"config_runtime\"], to_remove_ids)\n",
    "    data[\"node_config_feat\"] = np.delete(data[\"node_config_feat\"], to_remove_ids, axis=0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading valid data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/default/valid/unet_3d.4x4.bf16.npz\n",
      "Pruning graph...\n",
      "Original graph has 3163 nodes and 5112 edges\n",
      "New graph has 223 nodes and 181 edges\n",
      "Removing 496 duplicated node configs out of 1965\n",
      "/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/default/valid/mlperf_bert_batch_24_2x2.npz\n",
      "Pruning graph...\n",
      "Original graph has 19541 nodes and 30520 edges\n",
      "New graph has 4807 nodes and 4498 edges\n",
      "Removing 547 duplicated node configs out of 6048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:03<00:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/default/valid/inception_v3_batch_128_train.npz\n",
      "Pruning graph...\n",
      "Original graph has 12067 nodes and 21319 edges\n",
      "New graph has 1059 nodes and 1084 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:03<00:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 670 duplicated node configs out of 5984\n",
      "/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/default/valid/resnet50.4x4.fp16.npz\n",
      "Pruning graph...\n",
      "Original graph has 5673 nodes and 9099 edges\n",
      "New graph has 493 nodes and 495 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [00:04<00:02,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 602 duplicated node configs out of 6120\n",
      "/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/default/valid/resnet_v1_50_official_batch_128_bf16.npz\n",
      "Pruning graph...\n",
      "Original graph has 6135 nodes and 10670 edges\n",
      "New graph has 488 nodes and 493 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [00:04<00:01,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 764 duplicated node configs out of 8512\n",
      "/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/default/valid/tf2_bert_pretrain_dynamic_batch_size.npz\n",
      "Pruning graph...\n",
      "Original graph has 21664 nodes and 38485 edges\n",
      "New graph has 3889 nodes and 3480 edges\n",
      "Removing 1821 duplicated node configs out of 18160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [00:11<00:02,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/default/valid/bert_pretraining.4x4.fp16.npz\n",
      "Pruning graph...\n",
      "Original graph has 21335 nodes and 37236 edges\n",
      "New graph has 3538 nodes and 3283 edges\n",
      "Removing 1934 duplicated node configs out of 19232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:18<00:00,  2.62s/it]\n"
     ]
    }
   ],
   "source": [
    "dst_dir = root / f\"{collection}_pruned\" / ctype\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    print(\"Loading {} data...\".format(split))\n",
    "    split_src_dir = root / collection / ctype / split\n",
    "    split_dst_dir = dst_dir / split\n",
    "    split_dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for npz_path in tqdm(list(split_src_dir.glob(\"*.npz\"))):\n",
    "        print(npz_path)\n",
    "        data = dict(np.load(str(npz_path), allow_pickle=True))\n",
    "        data = prune_graph(data)\n",
    "        if split == \"train\":\n",
    "            data = remove_dupplicated_node_configs(data)\n",
    "        np.savez(split_dst_dir / npz_path.name, **data)\n",
    "        if split == \"valid\":\n",
    "            data = remove_dupplicated_node_configs(data)\n",
    "            dedup_dst_dir = Path(str(split_dst_dir).replace(\"valid\", \"valid_dedup\"))\n",
    "            dedup_dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "            np.savez(dedup_dst_dir / npz_path.name, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_src_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_default = dict(np.load(str(\"/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/default/valid/bert_pretraining.4x4.fp16.npz\"), allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_random = dict(np.load(str(\"/home/edu/code/google_fast_or_slow/data/npz_all/npz/layout/xla/random/valid/bert_pretraining.4x4.fp16.npz\"), allow_pickle=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_tpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
